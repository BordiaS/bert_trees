{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_tree_path = '/misc/vlgscratch4/BowmanGroup/datasets/bert_trees/ud_eng_pud_with_type.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ref_tree_path, 'r') as f_ref:\n",
    "    ref_trees = json.load(f_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '“While much of the digital transition is unprecedented in the United States, the peaceful transition of power is not,” Obama special assistant Kori Schulman wrote in a blog post Monday.\\n', 'dependencies': [[[1, 20], 'punct'], [[2, 9], 'mark'], [[3, 9], 'nsubj'], [[4, 7], 'case'], [[5, 7], 'det'], [[6, 7], 'amod'], [[7, 3], 'nmod'], [[8, 9], 'cop'], [[9, 20], 'advcl'], [[10, 13], 'case'], [[11, 13], 'det'], [[12, 13], 'compound'], [[13, 9], 'obl'], [[14, 20], 'punct'], [[15, 17], 'det'], [[16, 17], 'amod'], [[17, 20], 'nsubj'], [[18, 19], 'case'], [[19, 17], 'nmod'], [[20, 0], 'root'], [[21, 20], 'advmod'], [[22, 20], 'punct'], [[23, 20], 'punct'], [[24, 26], 'compound'], [[25, 26], 'amod'], [[26, 29], 'nsubj'], [[27, 26], 'flat'], [[28, 26], 'flat'], [[29, 20], 'parataxis'], [[30, 33], 'case'], [[31, 33], 'det'], [[32, 33], 'compound'], [[33, 29], 'obl'], [[34, 29], 'nmod:tmod'], [[35, 20], 'punct']], 'tokens': ['“', 'While', 'much', 'of', 'the', 'digital', 'transition', 'is', 'unprecedented', 'in', 'the', 'United', 'States', ',', 'the', 'peaceful', 'transition', 'of', 'power', 'is', 'not', ',', '”', 'Obama', 'special', 'assistant', 'Kori', 'Schulman', 'wrote', 'in', 'a', 'blog', 'post', 'Monday', '.'], 'dep_type': 'punct'}\n"
     ]
    }
   ],
   "source": [
    "for key in ref_trees:\n",
    "    print(ref_trees[key])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from bertviz import attention, visualization\n",
    "from bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import random\n",
    "\n",
    "bert_version = 'bert-large-uncased'\n",
    "model = BertModel.from_pretrained(bert_version)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_version)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=ref_trees[key]['sentence']\n",
    "dependencies = ref_trees[key]['dependencies']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens_a_delim = ['[CLS]'] + tokens + ['[SEP]']\n",
    "token_ids =  tokenizer.convert_tokens_to_ids(tokens_a_delim)\n",
    "tokens_tensor = torch.tensor([token_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_tokens=ref_trees[key]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_type_tensor = torch.LongTensor([[0] * len(tokens_a_delim)])\n",
    "_, _, attn_data_list =  model(tokens_tensor, token_type_ids=token_type_tensor)\n",
    "attn_tensor = torch.stack([attn_data['attn_probs'] for attn_data in attn_data_list])\n",
    "attention = attn_tensor.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_path = '/misc/vlgscratch4/BowmanGroup/datasets/ptb_trees/ptb3-wsj-test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wsj_path) as fwsj:\n",
    "    wsj_data = json.load(fwsj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_map(raw_gold_tokens, raw_bert_tokens):\n",
    "    gold_tokens = [strip_accents(s.lower()) for s in raw_gold_tokens]\n",
    "    bert_tokens = [s.replace(\"##\", \"\") for s in raw_bert_tokens[1:-1]]\n",
    "\n",
    "    gold_i = 0\n",
    "    bert_i = 0\n",
    "    gold_result = []\n",
    "    bert_result = []\n",
    "    while True:\n",
    "        if gold_i == len(gold_tokens) and bert_i == len(bert_tokens):\n",
    "            break\n",
    "        elif gold_tokens[gold_i] == bert_tokens[bert_i]:\n",
    "            gold_result.append((gold_i,))\n",
    "            bert_result.append((bert_i,))\n",
    "            gold_i += 1\n",
    "            bert_i += 1\n",
    "        elif len(bert_tokens[bert_i]) != len(gold_tokens[gold_i]):\n",
    "            sub_bert_i_ls = [bert_i]\n",
    "            sub_gold_i_ls = [gold_i]\n",
    "            sub_gold_token = gold_tokens[gold_i]\n",
    "            sub_bert_token = bert_tokens[bert_i]\n",
    "            bert_i += 1\n",
    "            gold_i += 1\n",
    "            while len(sub_bert_token) != len(sub_gold_token):\n",
    "                if len(sub_bert_token) < len(sub_gold_token):\n",
    "                    sub_bert_i_ls.append(bert_i)\n",
    "                    sub_bert_token += bert_tokens[bert_i]\n",
    "                    bert_i += 1\n",
    "                else:\n",
    "                    sub_gold_i_ls.append(gold_i)\n",
    "                    sub_gold_token += gold_tokens[gold_i]\n",
    "                    gold_i += 1\n",
    "            assert sub_bert_token == sub_gold_token\n",
    "            bert_result.append(tuple(sub_bert_i_ls))\n",
    "            gold_result.append(tuple(sub_gold_i_ls))\n",
    "        else:\n",
    "            raise Exception\n",
    "    return gold_result, bert_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = np.squeeze(attention, 1)\n",
    "layers, heads, _ , _ = attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_relations(attn_matrix):\n",
    "    max_relations = attn_arr.argmax(axis=1)+1\n",
    "    return list(zip(range(1,len(max_relations+1)),max_relations.tolist())) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_arr = attention[1, 1, 1:-1, 1:-1]\n",
    "max_rel=max_relations(attn_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 15),\n",
       " (2, 38),\n",
       " (3, 38),\n",
       " (4, 38),\n",
       " (5, 38),\n",
       " (6, 38),\n",
       " (7, 38),\n",
       " (8, 38),\n",
       " (9, 38),\n",
       " (10, 15),\n",
       " (11, 38),\n",
       " (12, 38),\n",
       " (13, 38),\n",
       " (14, 38),\n",
       " (15, 38),\n",
       " (16, 15),\n",
       " (17, 38),\n",
       " (18, 15),\n",
       " (19, 38),\n",
       " (20, 38),\n",
       " (21, 15),\n",
       " (22, 38),\n",
       " (23, 38),\n",
       " (24, 38),\n",
       " (25, 38),\n",
       " (26, 38),\n",
       " (27, 38),\n",
       " (28, 38),\n",
       " (29, 38),\n",
       " (30, 38),\n",
       " (31, 38),\n",
       " (32, 38),\n",
       " (33, 38),\n",
       " (34, 38),\n",
       " (35, 38),\n",
       " (36, 38),\n",
       " (37, 38)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(dependencies, relation_types):\n",
    "    value_list = []\n",
    "    \n",
    "    for ref_c in dependencies:\n",
    "        if tuple(ref_c[0]) in sys_tree:\n",
    "                correct_type[ref_c[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(ref_trees, sys_trees, mode='sys'):\n",
    "    '''\n",
    "        return:\n",
    "            mean F1 score\n",
    "    '''\n",
    "    prec_list = []\n",
    "    reca_list = []\n",
    "    f1_list = []\n",
    "    correct_type = Counter()\n",
    "    total_type = Counter()\n",
    "    assert len(ref_trees)==len(sys_trees), \"ref and sys should have same number of sentences\"\n",
    "\n",
    "    for i in ref_trees:\n",
    "        ref_tree = set(tuple(x[0]) for x in ref_trees[i]['dependencies'])\n",
    "\n",
    "    assert len(ref_trees)==len(sys_trees), \"ref and sys should have same number of sentences\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_tree_path=\"/misc/vlgscratch4/BowmanGroup/pmh330/LINGA_outputs/bert_large_ud/relations_bert_large__layer01__head01.json\"\n",
    "with open(sys_tree_path, 'r') as f_sys:\n",
    "    sys_trees = json.load(f_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 20),\n",
       " (2, 9),\n",
       " (3, 9),\n",
       " (4, 7),\n",
       " (5, 7),\n",
       " (6, 7),\n",
       " (7, 3),\n",
       " (8, 9),\n",
       " (9, 20),\n",
       " (10, 13),\n",
       " (11, 13),\n",
       " (12, 13),\n",
       " (13, 9),\n",
       " (14, 20),\n",
       " (15, 17),\n",
       " (16, 17),\n",
       " (17, 20),\n",
       " (18, 19),\n",
       " (19, 17),\n",
       " (20, 0),\n",
       " (21, 20),\n",
       " (22, 20),\n",
       " (23, 20),\n",
       " (24, 26),\n",
       " (25, 26),\n",
       " (26, 29),\n",
       " (27, 26),\n",
       " (28, 26),\n",
       " (29, 20),\n",
       " (30, 33),\n",
       " (31, 33),\n",
       " (32, 33),\n",
       " (33, 29),\n",
       " (34, 29),\n",
       " (35, 20)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ref_trees:\n",
    "    ref_tree = set(tuple(x[0]) for x in ref_trees[i]['dependencies'])\n",
    "    sys_tree = set(tuple(x) for x in sys_trees[i]['dependencies'])\n",
    "    break\n",
    "ref_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 5),\n",
       " (2, 14),\n",
       " (3, 14),\n",
       " (4, 15),\n",
       " (5, 15),\n",
       " (6, 10),\n",
       " (7, 5),\n",
       " (8, 5),\n",
       " (9, 15),\n",
       " (10, 15),\n",
       " (11, 15),\n",
       " (12, 5),\n",
       " (13, 5),\n",
       " (14, 14),\n",
       " (15, 15),\n",
       " (16, 5),\n",
       " (17, 5),\n",
       " (18, 15),\n",
       " (19, 28),\n",
       " (20, 10),\n",
       " (21, 5),\n",
       " (22, 14),\n",
       " (23, 15),\n",
       " (24, 5),\n",
       " (25, 5),\n",
       " (26, 28),\n",
       " (27, 5),\n",
       " (28, 14),\n",
       " (29, 5),\n",
       " (30, 10),\n",
       " (31, 15),\n",
       " (32, 5),\n",
       " (33, 5),\n",
       " (34, 5),\n",
       " (35, 15)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
